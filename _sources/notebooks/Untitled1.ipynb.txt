{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-79688cb98f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0minput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mtarget_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_input' is not defined"
     ]
    }
   ],
   "source": [
    "# CREATE PYMC3 + THEANO IMPLEMENTATION OF A SIMPLE RECURRENT NETWORK\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "from scipy.stats import mode\n",
    "theano.config.compute_test_value = 'ignore'\n",
    "input_dim = 2\n",
    "output_dim = 2\n",
    "### PARAMETERS OF THE MODEL ###\n",
    "hidden_dim = 64\n",
    "learning_rate = 0.1\n",
    "nb_epochs = 10\n",
    " \n",
    "np.random.seed(0)\n",
    " \n",
    "# Initialization /placeholder values\n",
    "X = T.dtensor3('X')\n",
    "Y = T.dtensor3('Y')\n",
    "  \n",
    "# generate data \n",
    "input_var = theano.shared(np.asarray(train_input).astype(np.float64))\n",
    "target_var = theano.shared(np.asarray(train_output).astype(np.float64))\n",
    " \n",
    "# Reference\n",
    "# From paper :IMPROVING PERFORMANCE OF RECURRENT NEURAL NETWORK WITH RELU NONLINEARITY\n",
    "def norm_positive_definite(r):\n",
    "    A = np.dot(r, r.transpose())/hidden_dim\n",
    "    values, vectors = np.linalg.eig(A)\n",
    "    e = np.amax(values)\n",
    "    Whh = A/e\n",
    "    return Whh\n",
    " \n",
    "def norm_weight(n_in, n_out):\n",
    "    low = 4 *-np.sqrt(6.0/(n_in + n_out))\n",
    "    high = 4 *np.sqrt(6.0/(n_in + n_out))\n",
    "    W = np.random.uniform(low=low, high=high, size=(n_in,n_out))\n",
    "    return W\n",
    "# weights of layer\n",
    "# initialize weights with random values\n",
    "init_1 = norm_weight(input_dim, hidden_dim)\n",
    "init_2 = norm_weight(hidden_dim, output_dim)\n",
    "init_h = norm_positive_definite(np.random.normal\n",
    "    (0, 1, (hidden_dim, hidden_dim)))\n",
    " \n",
    "\n",
    "W1 = theano.shared(init_1.astype(theano.config.floatX))\n",
    "W2 = theano.shared(init_2.astype(theano.config.floatX))\n",
    "Wh = theano.shared(init_h.astype(theano.config.floatX))\n",
    " \n",
    "# layer 1 which creates recurrence\n",
    "L1 = theano.shared(np.zeros((8, hidden_dim)).astype(theano.config.floatX))\n",
    " \n",
    "# define step\n",
    "def step(v, l_tm1, W1, W2, Wh):\n",
    "    layer1 = T.nnet.relu(T.dot(v, W1) + T.dot(l_tm1, Wh))\n",
    "    output_layer = T.nnet.sigmoid(T.dot(layer1, W2))\n",
    "    return [layer1, output_layer]\n",
    " \n",
    "\n",
    "# Computational graph\n",
    "[layer1s, predictions], updates = theano.scan(fn=step,\n",
    "                                        sequences=dict(input=X,taps=[0]),\n",
    "                                        outputs_info=[L1, None],  # same format as step function\n",
    "                                        non_sequences=[W1, W2, Wh])\n",
    " \n",
    "def build_rnn():\n",
    "    print(\"Building network ...\")\n",
    " \n",
    "    W1=pm.Normal('w_in_1', 0, sd=1, \n",
    "                             shape=(input_dim, hidden_dim), \n",
    "                             testval=init_1.astype(np.float64))\n",
    "    # Weights from 1st to 2nd layer\n",
    "    W2=pm.Normal('w_2_out', 0, sd=1, \n",
    "                            shape=(hidden_dim, output_dim), \n",
    "                            testval=init_2.astype(np.float64))\n",
    "     \n",
    "    # Weights from hidden layer to output\n",
    "    Wh=pm.Normal('w_1_2', 0, sd=1, \n",
    "                              shape=(hidden_dim,hidden_dim), \n",
    "                              testval=init_h.astype(np.float64))\n",
    " \n",
    "    prediction = theano.function(inputs = [X], outputs = predictions)\n",
    "     \n",
    " \n",
    "    return prediction\n",
    " \n",
    "with pm.Model() as rnn:\n",
    "    prediction = build_rnn()\n",
    "    pres = prediction(input_var.get_value())\n",
    "    out = pm.Bernoulli('out',pres,observed=target_var)\n",
    "     \n",
    "with rnn:\n",
    "    #Run ADVI which returns posterior means, standard deviations, \n",
    "    #and the evidence lower bound (ELBO)\n",
    "    v_params = pm.variational.advi(n=50000)\n",
    "    trace = pm.variational.sample_vp(v_params, draws=5000)\n",
    "\n",
    "# Replace shared variables with testing set\n",
    "input_var.set_value(np.asarray(test_input).astype(np.float64))\n",
    "target_var.set_value(np.asarray(test_output).astype(np.float64))\n",
    " \n",
    "with rnn:\n",
    "    # Creater posterior predictive samples\n",
    "    ppc = pm.sample_ppc(trace, samples=500)\n",
    "\n",
    "# Use probability of > 0.5 to assume prediction of class 1\n",
    " \n",
    "pred = ppc['out'].mean(axis=0) > 0.5\n",
    "            \n",
    "print (pred.shape)\n",
    " \n",
    "print('Accuracy = {}%'.format((test_output == pred).mean() * 100))\n",
    " \n",
    "stop = timeit.default_timer()\n",
    " \n",
    "print ('It took', stop-start, 'secs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
